{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load package and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:55:52.727905Z",
     "start_time": "2021-11-22T06:55:52.685003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['${CONFIG_AI_PATH}/notebooks/text_span_classify',\n",
       " '/nfs/pony/chenhao/workspace/python-snippets',\n",
       " '${CONFIG_AI_PATH}',\n",
       " '/nfs/pony/chenhao/workspace/bert4keras',\n",
       " '${CONFIG_AI_PATH}/notebooks/text_span_classify',\n",
       " '/nfs/pony/chenhao/envs/config_ai/lib/python38.zip',\n",
       " '/nfs/pony/chenhao/envs/config_ai/lib/python3.8',\n",
       " '/nfs/pony/chenhao/envs/config_ai/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/nfs/pony/chenhao/envs/config_ai/lib/python3.8/site-packages',\n",
       " '/nfs/pony/chenhao/envs/config_ai/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/mnt/raid4/home/chenhao/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:55:52 [INFO][backend.py:57]:setting tensorflow config...\n",
      "2021-11-22 14:55:52 [INFO][backend.py:61]:current devices:\n",
      "2021-11-22 14:55:52 [INFO][backend.py:62]:cpus:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "2021-11-22 14:55:52 [INFO][backend.py:63]:gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2021-11-22 14:55:52 [INFO][backend.py:64]:setting gpu memory allow growth...\n",
      "2021-11-22 14:55:52 [INFO][backend.py:67]:setting soft device placement...\n",
      "2021-11-22 14:55:52 [INFO][backend.py:71]:set tf config done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path\n",
    "\n",
    "from config_ai.models.text_span_classify import SeqLabelingModel\n",
    "from config_ai.models.text_span_classify.common import *\n",
    "\n",
    "from config_ai.evaluate import eval_text_span_classify\n",
    "from config_ai.data_utils import *\n",
    "from config_ai.backend import set_tf_config\n",
    "from config_ai.models import load_model\n",
    "from config_ai.experiments import get_model_config\n",
    "from config_ai.utils import read_config\n",
    "from snippets.utils import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "set_tf_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:55:55.779805Z",
     "start_time": "2021-11-22T06:55:55.568914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:55:55 [INFO][utils.py:100]:parsing config with path:${CONFIG_AI_PATH}/examples/text_span_classify/ner_seq_labeling.ini\n",
      "2021-11-22 14:55:55 [INFO][utils.py:111]:loading base config...\n",
      "2021-11-22 14:55:55 [INFO][utils.py:100]:parsing config with path:${CONFIG_AI_PATH}/examples/base_config.ini\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'common_config': {'experiment_dir': '/nfs/pony/chenhao/experiment',\n",
       "  'project_name': 'config_ai_example',\n",
       "  'is_train': True,\n",
       "  'is_test': True,\n",
       "  'is_save': True,\n",
       "  'save_args': {'format': 'h5', 'tf_serving_version': 1},\n",
       "  'eval_phase_list': ['train', 'dev'],\n",
       "  'output_phase_list': ['train', 'dev', 'test'],\n",
       "  'is_overwrite_experiment': True,\n",
       "  'default_random_seed': 10,\n",
       "  'base_config': '${CONFIG_AI_PATH}/examples/base_config.ini',\n",
       "  'model_cls': 'SeqLabelingModel',\n",
       "  'model_name': 'seq_labeling_example'},\n",
       " 'tokenizer_config': {'tokenizer_name': 'bert_word_piece',\n",
       "  'tokenizer_args': {'vocabs': '/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt'}},\n",
       " 'nn_model_config': {'pretrained_model_tag': 'bert',\n",
       "  'pretrained_model_path': '/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12'},\n",
       " 'compile_config': {'optimizer_name': 'adam',\n",
       "  'optimizer_args': {'learning_rate': 3e-05}},\n",
       " 'train_config': {'epochs': 5, 'batch_size': 32, 'overwrite_cache': False},\n",
       " 'test_config': {'batch_size': 64, 'overwrite_cache': False},\n",
       " 'callback_config': {'tensorboard_callback': True},\n",
       " 'data_config': {'train_data_path': '${CONFIG_AI_PATH}/data/ner/labeled.jsonl',\n",
       "  'eval_data_path': '${CONFIG_AI_PATH}/data/ner/labeled.jsonl',\n",
       "  'test_data_path': '${CONFIG_AI_PATH}/data/ner/labeled.jsonl'},\n",
       " 'task_config': {'label_file_path': '${CONFIG_AI_PATH}/data/ner/labels.txt',\n",
       "  'max_len': 60,\n",
       "  'multi_label': False,\n",
       "  'seq_label_strategy': 'BIO'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:55:55 [INFO][core.py:47]:init model with config:\n",
      "2021-11-22 14:55:55 [INFO][core.py:124]:initializing tokenizer with config:\n",
      "{\n",
      "    \"tokenizer_name\": \"bert_word_piece\",\n",
      "    \"tokenizer_args\": {\n",
      "        \"vocabs\": \"/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt\"\n",
      "    }\n",
      "}\n",
      "2021-11-22 14:55:55 [INFO][core.py:138]:tokenizer initialized with 21128 vocabs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B_company': 1,\n",
       " 'I_company': 2,\n",
       " 'B_name': 3,\n",
       " 'I_name': 4,\n",
       " 'B_position': 5,\n",
       " 'I_position': 6,\n",
       " 'B_government': 7,\n",
       " 'I_government': 8,\n",
       " 'B_organization': 9,\n",
       " 'I_organization': 10,\n",
       " 'B_movie': 11,\n",
       " 'I_movie': 12,\n",
       " 'B_address': 13,\n",
       " 'I_address': 14,\n",
       " 'B_book': 15,\n",
       " 'I_book': 16,\n",
       " 'B_scene': 17,\n",
       " 'I_scene': 18,\n",
       " 'B_game': 19,\n",
       " 'I_game': 20}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"${CONFIG_AI_PATH}/examples/text_span_classify/ner_seq_labeling.ini\"\n",
    "\n",
    "config = read_config(config_path)\n",
    "config\n",
    "model_config = get_model_config(config)\n",
    "# model_config\n",
    "\n",
    "model = SeqLabelingModel(config=model_config)\n",
    "model.label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:55:57.835221Z",
     "start_time": "2021-11-22T06:55:57.666881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'${CONFIG_AI_PATH}/data/ner/labeled.jsonl: 4 items'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'${CONFIG_AI_PATH}/data/ner/labeled.jsonl: 4 items'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'${CONFIG_AI_PATH}/data/ner/labeled.jsonl: 4 items'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabeledTextSpanClassifyExample(text='浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，', text_spans=[TextSpan(text='叶老桂', span=(9, 12), label='name', prob=1.0), TextSpan(text='浙商银行', span=(0, 4), label='company', prob=1.0)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = config['data_config']['train_data_path']\n",
    "train_data = model.jload_lines(train_data_path)\n",
    "f\"{train_data_path}: {len(train_data)} items\"\n",
    "\n",
    "\n",
    "eval_data_path = config['data_config']['eval_data_path']\n",
    "eval_data = model.jload_lines(eval_data_path)\n",
    "f\"{eval_data_path}: {len(eval_data)} items\"\n",
    "\n",
    "\n",
    "test_data_path = config['data_config']['test_data_path']\n",
    "test_data = model.jload_lines(test_data_path)\n",
    "f\"{test_data_path}: {len(test_data)} items\"\n",
    "\n",
    "\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:55:58.953916Z",
     "start_time": "2021-11-22T06:55:58.892905Z"
    }
   },
   "outputs": [],
   "source": [
    "data_manager = DataManager.get_instance(model=model, data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:55:59.551682Z",
     "start_time": "2021-11-22T06:55:59.523201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，',\n",
       " 'text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，',\n",
       " 'extra_text': None,\n",
       " 'token_ids': [101,\n",
       "  3851,\n",
       "  1555,\n",
       "  7213,\n",
       "  6121,\n",
       "  821,\n",
       "  689,\n",
       "  928,\n",
       "  6587,\n",
       "  6956,\n",
       "  1383,\n",
       "  5439,\n",
       "  3424,\n",
       "  1300,\n",
       "  1894,\n",
       "  1156,\n",
       "  794,\n",
       "  1369,\n",
       "  671,\n",
       "  702,\n",
       "  6235,\n",
       "  2428,\n",
       "  2190,\n",
       "  758,\n",
       "  6887,\n",
       "  7305,\n",
       "  3546,\n",
       "  6822,\n",
       "  6121,\n",
       "  749,\n",
       "  6237,\n",
       "  6438,\n",
       "  511,\n",
       "  1383,\n",
       "  5439,\n",
       "  3424,\n",
       "  6371,\n",
       "  711,\n",
       "  8024,\n",
       "  2190,\n",
       "  4680,\n",
       "  1184,\n",
       "  1744,\n",
       "  1079,\n",
       "  1555,\n",
       "  689,\n",
       "  7213,\n",
       "  6121,\n",
       "  5445,\n",
       "  6241,\n",
       "  8024,\n",
       "  102],\n",
       " 'segment_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'tokens': ['[CLS]',\n",
       "  '浙',\n",
       "  '商',\n",
       "  '银',\n",
       "  '行',\n",
       "  '企',\n",
       "  '业',\n",
       "  '信',\n",
       "  '贷',\n",
       "  '部',\n",
       "  '叶',\n",
       "  '老',\n",
       "  '桂',\n",
       "  '博',\n",
       "  '士',\n",
       "  '则',\n",
       "  '从',\n",
       "  '另',\n",
       "  '一',\n",
       "  '个',\n",
       "  '角',\n",
       "  '度',\n",
       "  '对',\n",
       "  '五',\n",
       "  '道',\n",
       "  '门',\n",
       "  '槛',\n",
       "  '进',\n",
       "  '行',\n",
       "  '了',\n",
       "  '解',\n",
       "  '读',\n",
       "  '。',\n",
       "  '叶',\n",
       "  '老',\n",
       "  '桂',\n",
       "  '认',\n",
       "  '为',\n",
       "  '，',\n",
       "  '对',\n",
       "  '目',\n",
       "  '前',\n",
       "  '国',\n",
       "  '内',\n",
       "  '商',\n",
       "  '业',\n",
       "  '银',\n",
       "  '行',\n",
       "  '而',\n",
       "  '言',\n",
       "  '，',\n",
       "  '[SEP]'],\n",
       " 'token2char': [(0, 0),\n",
       "  (0, 1),\n",
       "  (1, 2),\n",
       "  (2, 3),\n",
       "  (3, 4),\n",
       "  (4, 5),\n",
       "  (5, 6),\n",
       "  (6, 7),\n",
       "  (7, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 11),\n",
       "  (11, 12),\n",
       "  (12, 13),\n",
       "  (13, 14),\n",
       "  (14, 15),\n",
       "  (15, 16),\n",
       "  (16, 17),\n",
       "  (17, 18),\n",
       "  (18, 19),\n",
       "  (19, 20),\n",
       "  (20, 21),\n",
       "  (21, 22),\n",
       "  (22, 23),\n",
       "  (23, 24),\n",
       "  (24, 25),\n",
       "  (25, 26),\n",
       "  (26, 27),\n",
       "  (27, 28),\n",
       "  (28, 29),\n",
       "  (29, 30),\n",
       "  (30, 31),\n",
       "  (31, 32),\n",
       "  (32, 33),\n",
       "  (33, 34),\n",
       "  (34, 35),\n",
       "  (35, 36),\n",
       "  (36, 37),\n",
       "  (37, 38),\n",
       "  (38, 39),\n",
       "  (39, 40),\n",
       "  (40, 41),\n",
       "  (41, 42),\n",
       "  (42, 43),\n",
       "  (43, 44),\n",
       "  (44, 45),\n",
       "  (45, 46),\n",
       "  (46, 47),\n",
       "  (47, 48),\n",
       "  (48, 49),\n",
       "  (49, 50),\n",
       "  (0, 0)],\n",
       " 'char2token': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50],\n",
       " 'text_spans': [{'text': '叶老桂', 'span': (9, 12), 'label': 'name', 'prob': 1.0},\n",
       "  {'text': '浙商银行', 'span': (0, 4), 'label': 'company', 'prob': 1.0}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data_manager.get_features()\n",
    "feature = next(features)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:56:00.171018Z",
     "start_time": "2021-11-22T06:56:00.126154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'full_text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，',\n",
       " 'text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，',\n",
       " 'extra_text': None,\n",
       " 'token_ids': [101,\n",
       "  3851,\n",
       "  1555,\n",
       "  7213,\n",
       "  6121,\n",
       "  821,\n",
       "  689,\n",
       "  928,\n",
       "  6587,\n",
       "  6956,\n",
       "  1383,\n",
       "  5439,\n",
       "  3424,\n",
       "  1300,\n",
       "  1894,\n",
       "  1156,\n",
       "  794,\n",
       "  1369,\n",
       "  671,\n",
       "  702,\n",
       "  6235,\n",
       "  2428,\n",
       "  2190,\n",
       "  758,\n",
       "  6887,\n",
       "  7305,\n",
       "  3546,\n",
       "  6822,\n",
       "  6121,\n",
       "  749,\n",
       "  6237,\n",
       "  6438,\n",
       "  511,\n",
       "  1383,\n",
       "  5439,\n",
       "  3424,\n",
       "  6371,\n",
       "  711,\n",
       "  8024,\n",
       "  2190,\n",
       "  4680,\n",
       "  1184,\n",
       "  1744,\n",
       "  1079,\n",
       "  1555,\n",
       "  689,\n",
       "  7213,\n",
       "  6121,\n",
       "  5445,\n",
       "  6241,\n",
       "  8024,\n",
       "  102],\n",
       " 'segment_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'tokens': ['[CLS]',\n",
       "  '浙',\n",
       "  '商',\n",
       "  '银',\n",
       "  '行',\n",
       "  '企',\n",
       "  '业',\n",
       "  '信',\n",
       "  '贷',\n",
       "  '部',\n",
       "  '叶',\n",
       "  '老',\n",
       "  '桂',\n",
       "  '博',\n",
       "  '士',\n",
       "  '则',\n",
       "  '从',\n",
       "  '另',\n",
       "  '一',\n",
       "  '个',\n",
       "  '角',\n",
       "  '度',\n",
       "  '对',\n",
       "  '五',\n",
       "  '道',\n",
       "  '门',\n",
       "  '槛',\n",
       "  '进',\n",
       "  '行',\n",
       "  '了',\n",
       "  '解',\n",
       "  '读',\n",
       "  '。',\n",
       "  '叶',\n",
       "  '老',\n",
       "  '桂',\n",
       "  '认',\n",
       "  '为',\n",
       "  '，',\n",
       "  '对',\n",
       "  '目',\n",
       "  '前',\n",
       "  '国',\n",
       "  '内',\n",
       "  '商',\n",
       "  '业',\n",
       "  '银',\n",
       "  '行',\n",
       "  '而',\n",
       "  '言',\n",
       "  '，',\n",
       "  '[SEP]'],\n",
       " 'token2char': [(0, 0),\n",
       "  (0, 1),\n",
       "  (1, 2),\n",
       "  (2, 3),\n",
       "  (3, 4),\n",
       "  (4, 5),\n",
       "  (5, 6),\n",
       "  (6, 7),\n",
       "  (7, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 11),\n",
       "  (11, 12),\n",
       "  (12, 13),\n",
       "  (13, 14),\n",
       "  (14, 15),\n",
       "  (15, 16),\n",
       "  (16, 17),\n",
       "  (17, 18),\n",
       "  (18, 19),\n",
       "  (19, 20),\n",
       "  (20, 21),\n",
       "  (21, 22),\n",
       "  (22, 23),\n",
       "  (23, 24),\n",
       "  (24, 25),\n",
       "  (25, 26),\n",
       "  (26, 27),\n",
       "  (27, 28),\n",
       "  (28, 29),\n",
       "  (29, 30),\n",
       "  (30, 31),\n",
       "  (31, 32),\n",
       "  (32, 33),\n",
       "  (33, 34),\n",
       "  (34, 35),\n",
       "  (35, 36),\n",
       "  (36, 37),\n",
       "  (37, 38),\n",
       "  (38, 39),\n",
       "  (39, 40),\n",
       "  (40, 41),\n",
       "  (41, 42),\n",
       "  (42, 43),\n",
       "  (43, 44),\n",
       "  (44, 45),\n",
       "  (45, 46),\n",
       "  (46, 47),\n",
       "  (47, 48),\n",
       "  (48, 49),\n",
       "  (49, 50),\n",
       "  (0, 0)],\n",
       " 'char2token': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50],\n",
       " 'text_spans': [{'text': '叶老桂', 'span': (9, 12), 'label': 'name', 'prob': 1.0},\n",
       "  {'text': '浙商银行', 'span': (0, 4), 'label': 'company', 'prob': 1.0}],\n",
       " 'target_token_label_sequence': ['O',\n",
       "  'B_company',\n",
       "  'I_company',\n",
       "  'I_company',\n",
       "  'I_company',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B_name',\n",
       "  'I_name',\n",
       "  'I_name',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'classify_labels': [0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = data_manager.get_records(mode=\"train\")\n",
    "next(records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build&compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:56:09.279061Z",
     "start_time": "2021-11-22T06:56:01.414881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained_model_tag': 'bert',\n",
       " 'pretrained_model_path': '/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:56:01.452370: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-11-22 14:56:01.459187: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3597740000 Hz\n",
      "2021-11-22 14:56:01.459665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563827a7f800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-22 14:56:01.459685: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-22 14:56:01.556875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563827b19d10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-22 14:56:01.556904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2021-11-22 14:56:01.558155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1\n",
      "coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\n",
      "2021-11-22 14:56:01.558204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 14:56:01.558224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-22 14:56:01.558240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-22 14:56:01.558256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-22 14:56:01.558272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-22 14:56:01.558287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-22 14:56:01.558303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-22 14:56:01.560328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-22 14:56:01.560375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 14:56:01.562020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-22 14:56:01.562036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-11-22 14:56:01.562044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-11-22 14:56:01.564162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10593 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:06:00.0, compute capability: 6.1)\n",
      "2021-11-22 14:56:01 [INFO][mirrored_strategy.py:500]:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "2021-11-22 14:56:01 [INFO][tf_core.py:126]:number of devices: 1, use SINGLE scope\n",
      "2021-11-22 14:56:01 [INFO][nn_models.py:56]:loading from pretrained weights: /nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/model.ckpt\n",
      "2021-11-22 14:56:09 [INFO][seq_labeling.py:89]:nn model's summary:\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:192]:Model: \"token_classify_model\"\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:193]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:190]:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:195]:==================================================================================================\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:190]:token_ids (InputLayer)          [(None, None)]       0                                            \n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:190]:segment_ids (InputLayer)        [(None, None)]       0                                            \n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:190]:model (Model)                   (None, None, 768)    44974080    token_ids[0][0]                  \n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:190]:                                                                 segment_ids[0][0]                \n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:190]:token_classifier (Dense)        (None, None, 21)     16149       model[1][0]                      \n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:257]:==================================================================================================\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:268]:Total params: 44,990,229\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:269]:Trainable params: 44,990,229\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:270]:Non-trainable params: 0\n",
      "2021-11-22 14:56:09 [INFO][layer_utils.py:271]:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7fa66c112220>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_args = dict(**config[\"nn_model_config\"])\n",
    "# nn_model_args.update(transformer_kwargs=dict(dropout_rate=0.3))\n",
    "nn_model_args\n",
    "\n",
    "model.build_model(**nn_model_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:56:23.816834Z",
     "start_time": "2021-11-22T06:56:22.704775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer_name': 'adam', 'optimizer_args': {'learning_rate': 3e-05}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:56:22 [INFO][seq_labeling.py:95]:compile model with optimizer_name:adam, optimizer_args:{'learning_rate': 3e-05}\n",
      "2021-11-22 14:56:22 [INFO][tf_core.py:126]:number of devices: 1, use SINGLE scope\n",
      "2021-11-22 14:56:23 [INFO][losses.py:101]:build loss layer with loss function:<function sparse_categorical_crossentropy at 0x7fa6b5e4bd30>\n",
      "2021-11-22 14:56:23 [INFO][seq_labeling.py:118]:training model's summary:\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:192]:Model: \"model_1\"\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:193]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:195]:==================================================================================================\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:token_ids (InputLayer)          [(None, None)]       0                                            \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:segment_ids (InputLayer)        [(None, None)]       0                                            \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:classify_labels (InputLayer)    [(None, None)]       0                                            \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:token_classify_model (Model)    (None, None, 21)     44990229    token_ids[0][0]                  \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:                                                                 segment_ids[0][0]                \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:pred_mask (Lambda)              (None, None)         0           token_ids[0][0]                  \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:loss_layer (LossLayer)          ()                   0           classify_labels[0][0]            \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:                                                                 token_classify_model[1][0]       \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:                                                                 pred_mask[0][0]                  \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:add_loss (AddLoss)              ()                   0           loss_layer[0][0]                 \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:metric_layer (MetricLayer)      ()                   0           classify_labels[0][0]            \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:                                                                 token_classify_model[1][0]       \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:                                                                 pred_mask[0][0]                  \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:190]:add_metric (AddMetric)          ()                   0           metric_layer[0][0]               \n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:257]:==================================================================================================\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:268]:Total params: 44,990,229\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:269]:Trainable params: 44,990,229\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:270]:Non-trainable params: 0\n",
      "2021-11-22 14:56:23 [INFO][layer_utils.py:271]:__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "compile_args = dict(**config[\"compile_config\"])\n",
    "# compile_args.update(rdrop_alpha=4)\n",
    "compile_args\n",
    "model.compile_model(**compile_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:56:25.939029Z",
     "start_time": "2021-11-22T06:56:25.907089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'token_ids:0' shape=(None, None) dtype=int32>,\n",
       " <tf.Tensor 'segment_ids:0' shape=(None, None) dtype=int32>,\n",
       " <tf.Tensor 'classify_labels:0' shape=(None, None) dtype=int32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'token_classify_model/Identity:0' shape=(None, None, 21) dtype=float32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'loss_layer/Identity:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.metrics.Mean at 0x7fa624633400>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model.inputs\n",
    "model.train_model.outputs\n",
    "model.train_model.losses\n",
    "model.train_model.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:56:26.622630Z",
     "start_time": "2021-11-22T06:56:26.581999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'token_ids': 'int32', 'segment_ids': 'int32', 'classify_labels': 'int32'},\n",
       " {'token_ids': (None,), 'segment_ids': (None,), 'classify_labels': (None,)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "({'token_ids': 'int32', 'segment_ids': 'int32'},\n",
       " {'token_ids': (None,), 'segment_ids': (None,)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_dataset_info(\"train\")\n",
    "model.get_dataset_info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:56:27.357881Z",
     "start_time": "2021-11-22T06:56:27.299648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_ids': array([[ 101, 3851, 1555, 7213, 6121,  821,  689,  928, 6587, 6956, 1383,\n",
       "         5439, 3424, 1300, 1894, 1156,  794, 1369,  671,  702, 6235, 2428,\n",
       "         2190,  758, 6887, 7305, 3546, 6822, 6121,  749, 6237, 6438,  511,\n",
       "         1383, 5439, 3424, 6371,  711, 8024, 2190, 4680, 1184, 1744, 1079,\n",
       "         1555,  689, 7213, 6121, 5445, 6241, 8024,  102]], dtype=int32),\n",
       " 'segment_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32),\n",
       " 'classify_labels': array([[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data_manager.get_train_dataset(batch_size=1)\n",
    "\n",
    "item = next(dataset.as_numpy_iterator())\n",
    "item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:03.108645Z",
     "start_time": "2021-11-22T06:56:33.773419Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 4,\n",
       " 'batch_size': 8,\n",
       " 'overwrite_cache': False,\n",
       " 'steps_per_epoch': 50,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 4154.83it/s]\n",
      "2021-11-22 14:56:33 [INFO][tf_core.py:173]:train on 4 tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:56:38.163391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 6s 115ms/step - loss: 0.7457 - accuracy: 0.8557\n",
      "Epoch 2/4\n",
      "50/50 [==============================] - 6s 118ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 3/4\n",
      "50/50 [==============================] - 6s 128ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 4/4\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 0.0046 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:57:03 [INFO][tf_core.py:189]:training finished\n"
     ]
    }
   ],
   "source": [
    "train_args = dict(**config[\"train_config\"])\n",
    "train_args.update(epochs=4,steps_per_epoch=50, batch_size=8, verbose=1)\n",
    "train_args\n",
    "\n",
    "model.train(train_data=train_data, **train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict&evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:06.983294Z",
     "start_time": "2021-11-22T06:57:06.781145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledTextSpanClassifyExample(text='浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，', text_spans=[TextSpan(text='叶老桂', span=(9, 12), label='name', prob=1.0), TextSpan(text='浙商银行', span=(0, 4), label='company', prob=1.0)]),\n",
       " LabeledTextSpanClassifyExample(text='生生不息CSOL生化狂潮让你填弹狂扫', text_spans=[TextSpan(text='CSOL', span=(4, 8), label='game', prob=1.0)]),\n",
       " LabeledTextSpanClassifyExample(text='那不勒斯vs锡耶纳以及桑普vs热那亚之上呢？', text_spans=[TextSpan(text='那不勒斯', span=(0, 4), label='organization', prob=1.0), TextSpan(text='锡耶纳', span=(6, 9), label='organization', prob=1.0), TextSpan(text='桑普', span=(11, 13), label='organization', prob=1.0), TextSpan(text='热那亚', span=(15, 18), label='organization', prob=1.0)]),\n",
       " LabeledTextSpanClassifyExample(text='加勒比海盗3：世界尽头》的去年同期成绩死死甩在身后，后者则即将赶超《变形金刚》，', text_spans=[TextSpan(text='加勒比海盗3：世界尽头》', span=(0, 12), label='movie', prob=1.0), TextSpan(text='《变形金刚》', span=(33, 39), label='movie', prob=1.0)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3584.88it/s]\n",
      "2021-11-22 14:57:06 [INFO][tf_core.py:204]:predicting with tf model...\n",
      "1it [00:00, 20.78it/s]\n",
      "2021-11-22 14:57:06 [INFO][decorators.py:28]:function:_model_predict cost:0.050 seconds\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:155]:tokens:['[CLS]', '浙', '商', '银', '行', '企', '业', '信', '贷', '部', '叶', '老', '桂', '博', '士', '则', '从', '另', '一', '个', '角', '度', '对', '五', '道', '门', '槛', '进', '行', '了', '解', '读', '。', '叶', '老', '桂', '认', '为', '，', '对', '目', '前', '国', '内', '商', '业', '银', '行', '而', '言', '，', '[SEP]']\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:0, token:[CLS], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9962774>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:1, token:浙, pred:('B_company', <tf.Tensor: shape=(), dtype=float32, numpy=0.99092907>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:2, token:商, pred:('I_company', <tf.Tensor: shape=(), dtype=float32, numpy=0.9949203>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:3, token:银, pred:('I_company', <tf.Tensor: shape=(), dtype=float32, numpy=0.99529475>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:4, token:行, pred:('I_company', <tf.Tensor: shape=(), dtype=float32, numpy=0.99575126>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:5, token:企, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991285>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:6, token:业, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991043>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:7, token:信, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9990963>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:8, token:贷, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99916124>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:9, token:部, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99914384>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:10, token:叶, pred:('B_name', <tf.Tensor: shape=(), dtype=float32, numpy=0.9921232>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:11, token:老, pred:('I_name', <tf.Tensor: shape=(), dtype=float32, numpy=0.99353456>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:12, token:桂, pred:('I_name', <tf.Tensor: shape=(), dtype=float32, numpy=0.9932836>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:13, token:博, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.998944>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:14, token:士, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99916315>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:15, token:则, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992685>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:16, token:从, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99926347>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:17, token:另, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99924767>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:18, token:一, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99925977>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:19, token:个, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992494>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:20, token:角, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99924564>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:21, token:度, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992518>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:22, token:对, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992624>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:23, token:五, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992392>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:24, token:道, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99924755>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:25, token:门, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99923766>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:26, token:槛, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992291>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:27, token:进, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99922895>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:28, token:行, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99922454>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:29, token:了, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992361>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:30, token:解, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992424>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:31, token:读, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99924123>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:32, token:。, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991892>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:33, token:叶, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9989178>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:34, token:老, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9990202>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:35, token:桂, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99892116>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:36, token:认, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99920976>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:37, token:为, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992015>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:38, token:，, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991967>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:39, token:对, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992355>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:40, token:目, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99922645>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:41, token:前, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99922156>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:42, token:国, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99921227>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:43, token:内, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99917114>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:44, token:商, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99904996>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:45, token:业, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9990376>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:46, token:银, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991211>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:47, token:行, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.999126>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:48, token:而, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992424>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:49, token:言, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992193>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:50, token:，, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991966>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:51, token:[SEP], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99627763>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:155]:tokens:['[CLS]', '生', '生', '不', '息', 'cs', '##ol', '生', '化', '狂', '潮', '让', '你', '填', '弹', '狂', '扫', '[SEP]']\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:0, token:[CLS], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9959462>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:1, token:生, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99908614>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:2, token:生, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99911064>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:3, token:不, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99908924>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:4, token:息, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99909306>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:5, token:cs, pred:('B_game', <tf.Tensor: shape=(), dtype=float32, numpy=0.9895271>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:6, token:##ol, pred:('I_game', <tf.Tensor: shape=(), dtype=float32, numpy=0.98989516>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:7, token:生, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99900717>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:8, token:化, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99906415>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:9, token:狂, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9990689>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:10, token:潮, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99911445>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:11, token:让, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99909186>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:12, token:你, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9990734>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:13, token:填, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991316>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:14, token:弹, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991273>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:15, token:狂, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991345>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:16, token:扫, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991491>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:17, token:[SEP], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99594814>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:155]:tokens:['[CLS]', '那', '不', '勒', '斯', 'vs', '锡', '耶', '纳', '以', '及', '桑', '普', 'vs', '热', '那', '亚', '之', '上', '呢', '？', '[SEP]']\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:0, token:[CLS], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99596316>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:1, token:那, pred:('B_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.99640155>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:2, token:不, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.9976369>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:3, token:勒, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.9977914>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:4, token:斯, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.9980185>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:5, token:vs, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99897885>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:6, token:锡, pred:('B_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.996451>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:7, token:耶, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.99770004>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:8, token:纳, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.99816656>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:9, token:以, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99904674>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:10, token:及, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9990339>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:11, token:桑, pred:('B_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.99650985>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:12, token:普, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.9977717>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:13, token:vs, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99906725>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:14, token:热, pred:('B_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.9965096>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:15, token:那, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.9975677>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:16, token:亚, pred:('I_organization', <tf.Tensor: shape=(), dtype=float32, numpy=0.99776316>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:17, token:之, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99906915>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:18, token:上, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99912435>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:19, token:呢, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991068>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:20, token:？, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.999033>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:21, token:[SEP], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99596345>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:155]:tokens:['[CLS]', '加', '勒', '比', '海', '盗', '3', '：', '世', '界', '尽', '头', '》', '的', '去', '年', '同', '期', '成', '绩', '死', '死', '甩', '在', '身', '后', '，', '后', '者', '则', '即', '将', '赶', '超', '《', '变', '形', '金', '刚', '》', '，', '[SEP]']\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:0, token:[CLS], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9964761>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:1, token:加, pred:('B_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9928402>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:2, token:勒, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9979663>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:3, token:比, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9979857>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:4, token:海, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9981298>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:5, token:盗, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9982666>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:6, token:3, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.99828255>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:7, token:：, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9983022>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:8, token:世, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9982533>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:9, token:界, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.99821836>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:10, token:尽, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.99813545>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:11, token:头, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9982179>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:12, token:》, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9982035>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:13, token:的, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992163>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:14, token:去, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99918896>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:15, token:年, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9991872>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:16, token:同, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99922097>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:17, token:期, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992091>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:18, token:成, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99921954>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:19, token:绩, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992242>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:20, token:死, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99926144>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:21, token:死, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992599>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:22, token:甩, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992274>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:23, token:在, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992501>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:24, token:身, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992397>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:25, token:后, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992513>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:26, token:，, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992447>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:27, token:后, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992384>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:28, token:者, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99924743>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:29, token:则, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992563>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:30, token:即, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99923444>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:31, token:将, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992441>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:32, token:赶, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99926513>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:33, token:超, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9992372>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:34, token:《, pred:('B_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.992923>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:35, token:变, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.99809974>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:36, token:形, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.99821967>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:37, token:金, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9982278>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:38, token:刚, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9982734>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:39, token:》, pred:('I_movie', <tf.Tensor: shape=(), dtype=float32, numpy=0.9981761>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:40, token:，, pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.99921703>)\n",
      "2021-11-22 14:57:06 [INFO][seq_labeling.py:158]:idx:41, token:[SEP], pred:('O', <tf.Tensor: shape=(), dtype=float32, numpy=0.9964779>)\n",
      "2021-11-22 14:57:06 [INFO][decorators.py:28]:function:_post_predict cost:0.112 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[TextSpan(text='浙商银行', span=(0, 4), label='company', prob=0.9909290671348572),\n",
       "  TextSpan(text='叶老桂', span=(9, 12), label='name', prob=0.9921231865882874)],\n",
       " [TextSpan(text='CSOL', span=(4, 8), label='game', prob=0.9895271062850952)],\n",
       " [TextSpan(text='那不勒斯', span=(0, 4), label='organization', prob=0.9964015483856201),\n",
       "  TextSpan(text='锡耶纳', span=(6, 9), label='organization', prob=0.9964510202407837),\n",
       "  TextSpan(text='桑普', span=(11, 13), label='organization', prob=0.996509850025177),\n",
       "  TextSpan(text='热那亚', span=(15, 18), label='organization', prob=0.9965096116065979)],\n",
       " [TextSpan(text='加勒比海盗3：世界尽头》', span=(0, 12), label='movie', prob=0.9928401708602905),\n",
       "  TextSpan(text='《变形金刚》', span=(33, 39), label='movie', prob=0.9929230213165283)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred = train_data[:4]\n",
    "to_pred\n",
    "\n",
    "pred = model.predict(to_pred, show_detail=True)\n",
    "pred[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:20.942449Z",
     "start_time": "2021-11-22T06:57:20.912675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，',\n",
       "  'text_spans': [{'text': '叶老桂',\n",
       "    'span': (9, 12),\n",
       "    'label': 'name',\n",
       "    'prob': 1.0},\n",
       "   {'text': '浙商银行', 'span': (0, 4), 'label': 'company', 'prob': 1.0}],\n",
       "  'predict': [TextSpan(text='浙商银行', span=(0, 4), label='company', prob=0.9909290671348572),\n",
       "   TextSpan(text='叶老桂', span=(9, 12), label='name', prob=0.9921231865882874)],\n",
       "  'tp_set': {('叶老桂', 'name', (9, 12)), ('浙商银行', 'company', (0, 4))},\n",
       "  'fp_set': set(),\n",
       "  'fn_set': set()},\n",
       " {'text': '生生不息CSOL生化狂潮让你填弹狂扫',\n",
       "  'text_spans': [{'text': 'CSOL',\n",
       "    'span': (4, 8),\n",
       "    'label': 'game',\n",
       "    'prob': 1.0}],\n",
       "  'predict': [TextSpan(text='CSOL', span=(4, 8), label='game', prob=0.9895271062850952)],\n",
       "  'tp_set': {('CSOL', 'game', (4, 8))},\n",
       "  'fp_set': set(),\n",
       "  'fn_set': set()},\n",
       " {'text': '那不勒斯vs锡耶纳以及桑普vs热那亚之上呢？',\n",
       "  'text_spans': [{'text': '那不勒斯',\n",
       "    'span': (0, 4),\n",
       "    'label': 'organization',\n",
       "    'prob': 1.0},\n",
       "   {'text': '锡耶纳', 'span': (6, 9), 'label': 'organization', 'prob': 1.0},\n",
       "   {'text': '桑普', 'span': (11, 13), 'label': 'organization', 'prob': 1.0},\n",
       "   {'text': '热那亚', 'span': (15, 18), 'label': 'organization', 'prob': 1.0}],\n",
       "  'predict': [TextSpan(text='那不勒斯', span=(0, 4), label='organization', prob=0.9964015483856201),\n",
       "   TextSpan(text='锡耶纳', span=(6, 9), label='organization', prob=0.9964510202407837),\n",
       "   TextSpan(text='桑普', span=(11, 13), label='organization', prob=0.996509850025177),\n",
       "   TextSpan(text='热那亚', span=(15, 18), label='organization', prob=0.9965096116065979)],\n",
       "  'tp_set': {('桑普', 'organization', (11, 13)),\n",
       "   ('热那亚', 'organization', (15, 18)),\n",
       "   ('那不勒斯', 'organization', (0, 4)),\n",
       "   ('锡耶纳', 'organization', (6, 9))},\n",
       "  'fp_set': set(),\n",
       "  'fn_set': set()},\n",
       " {'text': '加勒比海盗3：世界尽头》的去年同期成绩死死甩在身后，后者则即将赶超《变形金刚》，',\n",
       "  'text_spans': [{'text': '加勒比海盗3：世界尽头》',\n",
       "    'span': (0, 12),\n",
       "    'label': 'movie',\n",
       "    'prob': 1.0},\n",
       "   {'text': '《变形金刚》', 'span': (33, 39), 'label': 'movie', 'prob': 1.0}],\n",
       "  'predict': [TextSpan(text='加勒比海盗3：世界尽头》', span=(0, 12), label='movie', prob=0.9928401708602905),\n",
       "   TextSpan(text='《变形金刚》', span=(33, 39), label='movie', prob=0.9929230213165283)],\n",
       "  'tp_set': {('《变形金刚》', 'movie', (33, 39)),\n",
       "   ('加勒比海盗3：世界尽头》', 'movie', (0, 12))},\n",
       "  'fp_set': set(),\n",
       "  'fn_set': set()}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = get_text_span_classify_output(to_pred, pred)\n",
    "output_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:23.420835Z",
     "start_time": "2021-11-22T06:57:23.359237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detail': {'name': {'tp': 1,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'movie': {'tp': 2,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'organization': {'tp': 4,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'game': {'tp': 1,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'company': {'tp': 1,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0}},\n",
       " 'micro': {'tp': 9,\n",
       "  'fp': 0,\n",
       "  'fn': 0,\n",
       "  'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1': 1.0},\n",
       " 'macro': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_spans = [e.text_spans for e in to_pred]\n",
    "eval_rs = eval_text_span_classify(true_spans, pred)\n",
    "eval_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save&load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:26.863507Z",
     "start_time": "2021-11-22T06:57:24.898042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'h5'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/nfs/pony/chenhao/experiment/config_ai_example/seq_labeling_example/model'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:57:24 [INFO][core.py:79]:saving model to /nfs/pony/chenhao/experiment/config_ai_example/seq_labeling_example/model\n",
      "2021-11-22 14:57:24 [INFO][tf_core.py:55]:saving keras model to path:/nfs/pony/chenhao/experiment/config_ai_example/seq_labeling_example/model/nn_model/nn_model.h5\n",
      "2021-11-22 14:57:26 [INFO][core.py:144]:save model done\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(config[\"common_config\"][\"experiment_dir\"],\n",
    "                          config[\"common_config\"][\"project_name\"],\n",
    "                          config[\"common_config\"][\"model_name\"],\"model\")\n",
    "\n",
    "save_args = dict(**config[\"common_config\"][\"save_args\"])\n",
    "del save_args[\"tf_serving_version\"]\n",
    "\n",
    "save_args\n",
    "model_path\n",
    "\n",
    "\n",
    "model.save(path=model_path, **save_args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:30.990633Z",
     "start_time": "2021-11-22T06:57:27.776886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:57:27 [INFO][core.py:90]:loading model from path:/nfs/pony/chenhao/experiment/config_ai_example/seq_labeling_example/model\n",
      "2021-11-22 14:57:27 [INFO][core.py:47]:init model with config:\n",
      "2021-11-22 14:57:27 [INFO][core.py:124]:initializing tokenizer with config:\n",
      "{\n",
      "    \"tokenizer_name\": \"bert_word_piece\",\n",
      "    \"tokenizer_args\": {\n",
      "        \"vocabs\": \"/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt\"\n",
      "    }\n",
      "}\n",
      "2021-11-22 14:57:27 [INFO][core.py:138]:tokenizer initialized with 21128 vocabs\n",
      "2021-11-22 14:57:27 [INFO][tf_core.py:157]:loading keras model from path:/nfs/pony/chenhao/experiment/config_ai_example/seq_labeling_example/model/nn_model/nn_model.h5 with format:h5\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:192]:Model: \"token_classify_model\"\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:193]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:190]:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:195]:==================================================================================================\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:190]:token_ids (InputLayer)          [(None, None)]       0                                            \n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:190]:segment_ids (InputLayer)        [(None, None)]       0                                            \n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:190]:model (Model)                   (None, None, 768)    44974080    token_ids[0][0]                  \n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:190]:                                                                 segment_ids[0][0]                \n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:190]:token_classifier (Dense)        (None, None, 21)     16149       model[1][0]                      \n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:257]:==================================================================================================\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:268]:Total params: 44,990,229\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:269]:Trainable params: 44,990,229\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:270]:Non-trainable params: 0\n",
      "2021-11-22 14:57:30 [INFO][layer_utils.py:271]:__________________________________________________________________________________________________\n",
      "2021-11-22 14:57:30 [INFO][core.py:158]:load model done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<config_ai.models.text_span_classify.seq_labeling.SeqLabelingModel at 0x7fa6adaa14c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model(path=model_path)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:57:32.005790Z",
     "start_time": "2021-11-22T06:57:31.828742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2802.27it/s]\n",
      "2021-11-22 14:57:31 [INFO][tf_core.py:204]:predicting with tf model...\n",
      "2021-11-22 14:57:31 [INFO][decorators.py:28]:function:_model_predict cost:0.076 seconds\n",
      "2021-11-22 14:57:32 [INFO][decorators.py:28]:function:_post_predict cost:0.049 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[TextSpan(text='浙商银行', span=(0, 4), label='company', prob=0.9909290671348572),\n",
       "  TextSpan(text='叶老桂', span=(9, 12), label='name', prob=0.9921231865882874)],\n",
       " [TextSpan(text='CSOL', span=(4, 8), label='game', prob=0.9895271062850952)],\n",
       " [TextSpan(text='那不勒斯', span=(0, 4), label='organization', prob=0.9964015483856201),\n",
       "  TextSpan(text='锡耶纳', span=(6, 9), label='organization', prob=0.9964510202407837),\n",
       "  TextSpan(text='桑普', span=(11, 13), label='organization', prob=0.996509850025177),\n",
       "  TextSpan(text='热那亚', span=(15, 18), label='organization', prob=0.9965096116065979)],\n",
       " [TextSpan(text='加勒比海盗3：世界尽头》', span=(0, 12), label='movie', prob=0.9928401708602905),\n",
       "  TextSpan(text='《变形金刚》', span=(33, 39), label='movie', prob=0.9929230213165283)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pred = loaded_model.predict(data=to_pred)\n",
    "loaded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "config_ai",
   "language": "python",
   "name": "config_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "508px",
    "left": "1088px",
    "right": "20px",
    "top": "120px",
    "width": "333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
