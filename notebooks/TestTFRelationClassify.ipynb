{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load package and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:31:57.655431Z",
     "start_time": "2021-08-04T07:31:44.010391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:31:56 [INFO][backend.py:57]:setting tensorflow config...\n",
      "2021-08-04 15:31:57 [INFO][backend.py:61]:current devices:\n",
      "2021-08-04 15:31:57 [INFO][backend.py:62]:cpus:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "2021-08-04 15:31:57 [INFO][backend.py:63]:gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2021-08-04 15:31:57 [INFO][backend.py:64]:setting gpu memory allow growth...\n",
      "2021-08-04 15:31:57 [INFO][backend.py:67]:setting soft device placement...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "# sys.path\n",
    "\n",
    "from ai_schema import *\n",
    "from config_ai.backend import set_tf_config\n",
    "from config_ai.utils import *\n",
    "from config_ai.models.relation_classify.tf_relation_classify import TFRelationClassify\n",
    "from config_ai.models.relation_classify.common import *\n",
    "from config_ai.data_utils import *\n",
    "from config_ai.models import load_model\n",
    "from config_ai.experiments import get_model_config\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "set_tf_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:18.439673Z",
     "start_time": "2021-08-04T07:32:18.303129Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:32:18 [INFO][utils.py:283]:parsing config with path:./config/tf_rlation_classify_config.ini\n",
      "2021-08-04 15:32:18 [INFO][utils.py:294]:loading base config...\n",
      "2021-08-04 15:32:18 [INFO][utils.py:283]:parsing config with path:/nfs/pony/chenhao/workspace/ConfigAI/demo/tf_base_config.ini\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tokenizer_config': {'tokenizer_name': 'bert_word_piece',\n",
       "  'tokenizer_args': {'vocabs': '/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt'}},\n",
       " 'task_config': {'label_file_path': '/nfs/pony/chenhao/data/clue/wsc/labels.txt',\n",
       "  'text_span_label_path': '/nfs/pony/chenhao/data/clue/wsc/span_labels.txt',\n",
       "  'max_len': 128,\n",
       "  'multi_label': False,\n",
       "  'embedding_strategy': 'ENTITY_START'},\n",
       " 'model_name': 'tf_relation_classify_model'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:32:18 [INFO][core.py:42]:init model with config:\n",
      "2021-08-04 15:32:18 [INFO][core.py:45]:{\n",
      "    \"tokenizer_config\": {\n",
      "        \"tokenizer_name\": \"bert_word_piece\",\n",
      "        \"tokenizer_args\": {\n",
      "            \"vocabs\": \"/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt\"\n",
      "        }\n",
      "    },\n",
      "    \"task_config\": {\n",
      "        \"label_file_path\": \"/nfs/pony/chenhao/data/clue/wsc/labels.txt\",\n",
      "        \"text_span_label_path\": \"/nfs/pony/chenhao/data/clue/wsc/span_labels.txt\",\n",
      "        \"max_len\": 128,\n",
      "        \"multi_label\": false,\n",
      "        \"embedding_strategy\": \"ENTITY_START\"\n",
      "    },\n",
      "    \"model_name\": \"tf_relation_classify_model\",\n",
      "    \"model_cls\": \"TFRelationClassify\"\n",
      "}\n",
      "2021-08-04 15:32:18 [INFO][tf_relation_classify.py:70]:initializing tokenizer\n",
      "2021-08-04 15:32:18 [INFO][tf_relation_classify.py:77]:replacing special tokens:['[S:span]', '[O:span]', '[/S]', '[/O]'] to vocabs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'true', 1: 'false'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"./config/tf_rlation_classify_config.ini\"\n",
    "\n",
    "config = read_config(config_path)\n",
    "model_config = get_model_config(config)\n",
    "model_config\n",
    "\n",
    "model = TFRelationClassify(config=model_config)\n",
    "model.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:19.134929Z",
     "start_time": "2021-08-04T07:32:19.102672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenizer_name': 'bert_word_piece',\n",
       " 'tokenizer_args': {'vocabs': '/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['[S:span]',\n",
       " '[O:span]',\n",
       " '[/S]',\n",
       " '[/O]',\n",
       " '[unused14]',\n",
       " '[unused15]',\n",
       " '[unused16]',\n",
       " '[unused17]',\n",
       " '[unused18]',\n",
       " '[unused19]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer_config\n",
    "model.vocab_size\n",
    "model.tokenizer.vocabs[10:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:20.426893Z",
     "start_time": "2021-08-04T07:32:20.355238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/pony/chenhao/data/clue/wsc/sample.jsonl: 128 items'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/nfs/pony/chenhao/data/clue/wsc/sample.jsonl: 128 items'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/nfs/pony/chenhao/data/clue/wsc/sample.jsonl: 128 items'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabeledRelationClassifyExample(text='裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。', extra_text=None, text_span1=TextSpan(text='伤口', span=(3, 5), label='span', prob=1.0), text_span2=TextSpan(text='它们', span=(27, 29), label='span', prob=1.0), label=Label(name='false', prob=1.0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = config['data_config']['train_data_path']\n",
    "train_data = model.jload_lines(train_data_path)\n",
    "f\"{train_data_path}: {len(train_data)} items\"\n",
    "\n",
    "\n",
    "dev_data_path = config['data_config']['dev_data_path']\n",
    "dev_data = model.jload_lines(dev_data_path)\n",
    "f\"{dev_data_path}: {len(dev_data)} items\"\n",
    "\n",
    "\n",
    "test_data_path = config['data_config']['test_data_path']\n",
    "test_data = model.jload_lines(test_data_path)\n",
    "f\"{test_data_path}: {len(test_data)} items\"\n",
    "\n",
    "\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:21.178894Z",
     "start_time": "2021-08-04T07:32:21.150358Z"
    }
   },
   "outputs": [],
   "source": [
    "data_manager = DataManager.get_instance(model=model, data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:21.700909Z",
     "start_time": "2021-08-04T07:32:21.636042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_text': '裂开的[S:span]伤口[/S]涂满尘土，里面有碎石子和木头刺，我小心翼翼把[O:span]它们[/O]剔除出去。',\n",
       " 'text': '裂开的[S:span]伤口[/S]涂满尘土，里面有碎石子和木头刺，我小心翼翼把[O:span]它们[/O]剔除出去。',\n",
       " 'extra_text': None,\n",
       " 'token_ids': [101,\n",
       "  6162,\n",
       "  2458,\n",
       "  4638,\n",
       "  10,\n",
       "  839,\n",
       "  1366,\n",
       "  12,\n",
       "  3864,\n",
       "  4007,\n",
       "  2212,\n",
       "  1759,\n",
       "  8024,\n",
       "  7027,\n",
       "  7481,\n",
       "  3300,\n",
       "  4810,\n",
       "  4767,\n",
       "  2094,\n",
       "  1469,\n",
       "  3312,\n",
       "  1928,\n",
       "  1173,\n",
       "  8024,\n",
       "  2769,\n",
       "  2207,\n",
       "  2552,\n",
       "  5437,\n",
       "  5437,\n",
       "  2828,\n",
       "  11,\n",
       "  2124,\n",
       "  812,\n",
       "  13,\n",
       "  1188,\n",
       "  7370,\n",
       "  1139,\n",
       "  1343,\n",
       "  511,\n",
       "  102],\n",
       " 'segment_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'tokens': ['[CLS]',\n",
       "  '裂',\n",
       "  '开',\n",
       "  '的',\n",
       "  '[S:span]',\n",
       "  '伤',\n",
       "  '口',\n",
       "  '[/S]',\n",
       "  '涂',\n",
       "  '满',\n",
       "  '尘',\n",
       "  '土',\n",
       "  '，',\n",
       "  '里',\n",
       "  '面',\n",
       "  '有',\n",
       "  '碎',\n",
       "  '石',\n",
       "  '子',\n",
       "  '和',\n",
       "  '木',\n",
       "  '头',\n",
       "  '刺',\n",
       "  '，',\n",
       "  '我',\n",
       "  '小',\n",
       "  '心',\n",
       "  '翼',\n",
       "  '翼',\n",
       "  '把',\n",
       "  '[O:span]',\n",
       "  '它',\n",
       "  '们',\n",
       "  '[/O]',\n",
       "  '剔',\n",
       "  '除',\n",
       "  '出',\n",
       "  '去',\n",
       "  '。',\n",
       "  '[SEP]'],\n",
       " 'span_idxs': [4, 30, 7, 33],\n",
       " 'labels': ['false']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data_manager.get_features()\n",
    "feature = next(features)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:22.242098Z",
     "start_time": "2021-08-04T07:32:22.180745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'full_text': '裂开的[S:span]伤口[/S]涂满尘土，里面有碎石子和木头刺，我小心翼翼把[O:span]它们[/O]剔除出去。',\n",
       " 'text': '裂开的[S:span]伤口[/S]涂满尘土，里面有碎石子和木头刺，我小心翼翼把[O:span]它们[/O]剔除出去。',\n",
       " 'extra_text': None,\n",
       " 'token_ids': [101,\n",
       "  6162,\n",
       "  2458,\n",
       "  4638,\n",
       "  10,\n",
       "  839,\n",
       "  1366,\n",
       "  12,\n",
       "  3864,\n",
       "  4007,\n",
       "  2212,\n",
       "  1759,\n",
       "  8024,\n",
       "  7027,\n",
       "  7481,\n",
       "  3300,\n",
       "  4810,\n",
       "  4767,\n",
       "  2094,\n",
       "  1469,\n",
       "  3312,\n",
       "  1928,\n",
       "  1173,\n",
       "  8024,\n",
       "  2769,\n",
       "  2207,\n",
       "  2552,\n",
       "  5437,\n",
       "  5437,\n",
       "  2828,\n",
       "  11,\n",
       "  2124,\n",
       "  812,\n",
       "  13,\n",
       "  1188,\n",
       "  7370,\n",
       "  1139,\n",
       "  1343,\n",
       "  511,\n",
       "  102],\n",
       " 'segment_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'tokens': ['[CLS]',\n",
       "  '裂',\n",
       "  '开',\n",
       "  '的',\n",
       "  '[S:span]',\n",
       "  '伤',\n",
       "  '口',\n",
       "  '[/S]',\n",
       "  '涂',\n",
       "  '满',\n",
       "  '尘',\n",
       "  '土',\n",
       "  '，',\n",
       "  '里',\n",
       "  '面',\n",
       "  '有',\n",
       "  '碎',\n",
       "  '石',\n",
       "  '子',\n",
       "  '和',\n",
       "  '木',\n",
       "  '头',\n",
       "  '刺',\n",
       "  '，',\n",
       "  '我',\n",
       "  '小',\n",
       "  '心',\n",
       "  '翼',\n",
       "  '翼',\n",
       "  '把',\n",
       "  '[O:span]',\n",
       "  '它',\n",
       "  '们',\n",
       "  '[/O]',\n",
       "  '剔',\n",
       "  '除',\n",
       "  '出',\n",
       "  '去',\n",
       "  '。',\n",
       "  '[SEP]'],\n",
       " 'span_idxs': [4, 30, 7, 33],\n",
       " 'labels': ['false'],\n",
       " 'classify_output': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = data_manager.get_records(mode=\"train\")\n",
    "record = next(records)\n",
    "record\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build&compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:26.626216Z",
     "start_time": "2021-08-04T07:32:23.251397Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained_model_tag': 'bert',\n",
       " 'pretrained_model_path': '/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:32:23 [INFO][mirrored_strategy.py:500]:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "2021-08-04 15:32:23 [INFO][tf_core.py:126]:number of devices: 1, use SINGLE scope\n",
      "2021-08-04 15:32:23 [INFO][nn_models.py:56]:loading from pretrained weights: /nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/model.ckpt\n",
      "2021-08-04 15:32:26 [WARNING][deprecation.py:323]:From /home/chenhao/miniconda3/envs/chenhao-py3.6-tf2.0/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "2021-08-04 15:32:26 [INFO][tf_relation_classify.py:114]:nn model's summary:\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:192]:Model: \"model_1\"\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:193]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:195]:==================================================================================================\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:token_ids (InputLayer)          [(None, None)]       0                                            \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:segment_ids (InputLayer)        [(None, None)]       0                                            \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:span_idxs (InputLayer)          [(None, 4)]          0                                            \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:model (Model)                   (None, None, 768)    44974080    token_ids[0][0]                  \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:                                                                 segment_ids[0][0]                \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:tf_op_layer_strided_slice (Tens [(None, 2)]          0           span_idxs[0][0]                  \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:token_extract_layer (TokenExtra (None, 1536)         0           model[1][0]                      \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:190]:classify_layer (Dense)          (None, 2)            3074        token_extract_layer[0][0]        \n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:257]:==================================================================================================\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:268]:Total params: 44,977,154\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:269]:Trainable params: 44,977,154\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:270]:Non-trainable params: 0\n",
      "2021-08-04 15:32:26 [INFO][layer_utils.py:271]:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f623809c048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_args = dict(**config[\"nn_model_config\"])\n",
    "nn_model_args\n",
    "model.build_model(**nn_model_args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:29.090434Z",
     "start_time": "2021-08-04T07:32:28.853060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer_name': 'adam', 'optimizer_args': {'learning_rate': 3e-05}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:32:28 [INFO][tf_relation_classify.py:120]:compiling model...\n",
      "2021-08-04 15:32:28 [INFO][tf_core.py:126]:number of devices: 1, use SINGLE scope\n",
      "2021-08-04 15:32:29 [INFO][tf_relation_classify.py:137]:training model's summary:\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:192]:Model: \"model_2\"\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:193]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:195]:==================================================================================================\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:token_ids (InputLayer)          [(None, None)]       0                                            \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:segment_ids (InputLayer)        [(None, None)]       0                                            \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:span_idxs (InputLayer)          [(None, 4)]          0                                            \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:model (Model)                   (None, None, 768)    44974080    token_ids[0][0]                  \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:                                                                 segment_ids[0][0]                \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:tf_op_layer_strided_slice (Tens [(None, 2)]          0           span_idxs[0][0]                  \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:token_extract_layer (TokenExtra (None, 1536)         0           model[1][0]                      \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:classify_output (InputLayer)    [(None,)]            0                                            \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:classify_layer (Dense)          (None, 2)            3074        token_extract_layer[0][0]        \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:loss_layer (LossLayer)          (None,)              0           classify_output[0][0]            \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:                                                                 classify_layer[0][0]             \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:add_loss (AddLoss)              (None,)              0           loss_layer[0][0]                 \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:metric_layer (MetricLayer)      (None,)              0           classify_output[0][0]            \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:                                                                 classify_layer[0][0]             \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:190]:add_metric (AddMetric)          (None,)              0           metric_layer[0][0]               \n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:257]:==================================================================================================\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:268]:Total params: 44,977,154\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:269]:Trainable params: 44,977,154\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:270]:Non-trainable params: 0\n",
      "2021-08-04 15:32:29 [INFO][layer_utils.py:271]:__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "compile_args = dict(**config[\"compile_config\"])\n",
    "compile_args\n",
    "model.compile_model(**compile_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:31.266380Z",
     "start_time": "2021-08-04T07:32:31.228581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'token_ids:0' shape=(None, None) dtype=int32>,\n",
       " <tf.Tensor 'segment_ids:0' shape=(None, None) dtype=int32>,\n",
       " <tf.Tensor 'span_idxs:0' shape=(None, 4) dtype=int32>,\n",
       " <tf.Tensor 'classify_output:0' shape=(None,) dtype=int32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'classify_layer/Identity:0' shape=(None, 2) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'loss_layer/Identity:0' shape=(None,) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.metrics.Mean at 0x7f62187bfb00>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model.inputs\n",
    "model.train_model.outputs\n",
    "model.train_model.losses\n",
    "model.train_model.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:32.506532Z",
     "start_time": "2021-08-04T07:32:32.475123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'token_ids': 'int32',\n",
       "  'segment_ids': 'int32',\n",
       "  'span_idxs': 'int32',\n",
       "  'classify_output': 'int32'},\n",
       " {'token_ids': (None,),\n",
       "  'segment_ids': (None,),\n",
       "  'span_idxs': (4,),\n",
       "  'classify_output': ()})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "({'token_ids': 'int32', 'segment_ids': 'int32', 'span_idxs': 'int32'},\n",
       " {'token_ids': (None,), 'segment_ids': (None,), 'span_idxs': (4,)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._get_dataset_info(\"train\")\n",
    "model._get_dataset_info(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:32:58.458933Z",
     "start_time": "2021-08-04T07:32:33.791444Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 10, 'batch_size': 8, 'overwrite_cache': False, 'verbose': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1235.78it/s]\n",
      "2021-08-04 15:32:34 [INFO][tf_core.py:173]:train on 128 tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 0.7844 - accuracy: 0.4922\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.5762 - accuracy: 0.6797\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.4547 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.3218 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.2346 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 0.1857 - accuracy: 0.9297\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 0.1600 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 0.1270 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 0.1603 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 0.1176 - accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:32:58 [INFO][tf_core.py:188]:training finished\n"
     ]
    }
   ],
   "source": [
    "train_args = dict(**config[\"train_config\"])\n",
    "train_args.update(batch_size=8, verbose=1, epochs=10)\n",
    "train_args\n",
    "\n",
    "model.train(train_data=train_data, **train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict&evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:33:47.680680Z",
     "start_time": "2021-08-04T07:33:47.589290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledRelationClassifyExample(text='裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。', extra_text=None, text_span1=TextSpan(text='伤口', span=(3, 5), label='span', prob=1.0), text_span2=TextSpan(text='它们', span=(27, 29), label='span', prob=1.0), label=Label(name='false', prob=1.0)),\n",
       " LabeledRelationClassifyExample(text='裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。', extra_text=None, text_span1=TextSpan(text='尘土', span=(7, 9), label='span', prob=1.0), text_span2=TextSpan(text='它们', span=(27, 29), label='span', prob=1.0), label=Label(name='false', prob=1.0)),\n",
       " LabeledRelationClassifyExample(text='裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。', extra_text=None, text_span1=TextSpan(text='碎石子和木头刺', span=(13, 20), label='span', prob=1.0), text_span2=TextSpan(text='它们', span=(27, 29), label='span', prob=1.0), label=Label(name='true', prob=1.0)),\n",
       " LabeledRelationClassifyExample(text='这时候放在床上枕头旁边的手机响了，我感到奇怪，因为欠费已被停机两个月，现在它突然响了。', extra_text=None, text_span1=TextSpan(text='床', span=(5, 6), label='span', prob=1.0), text_span2=TextSpan(text='它', span=(37, 38), label='span', prob=1.0), label=Label(name='false', prob=1.0))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2543.16it/s]\n",
      "2021-08-04 15:33:47 [INFO][tf_core.py:204]:predicting with tf model...\n",
      "1it [00:00, 18.72it/s]\n",
      "2021-08-04 15:33:47 [INFO][utils.py:102]:function:_model_predict cost:0.055 seconds\n",
      "2021-08-04 15:33:47 [INFO][utils.py:102]:function:_post_predict cost:0.002 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Label(name='false', prob=0.9941636919975281),\n",
       " Label(name='false', prob=0.9980733394622803),\n",
       " Label(name='true', prob=0.9973798394203186),\n",
       " Label(name='false', prob=0.9944508075714111)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred = train_data[:4]\n",
    "to_pred\n",
    "\n",
    "pred = model.predict(to_pred, show_detail=True, threshold=0.999)\n",
    "pred[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:34:37.300548Z",
     "start_time": "2021-08-04T07:34:37.267532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。',\n",
       "  'extra_text': None,\n",
       "  'text_span1': {'text': '伤口', 'span': (3, 5), 'label': 'span', 'prob': 1.0},\n",
       "  'text_span2': {'text': '它们', 'span': (27, 29), 'label': 'span', 'prob': 1.0},\n",
       "  'label': {'name': 'false', 'prob': 1.0},\n",
       "  'predict': {'name': 'false', 'prob': 0.9941636919975281}},\n",
       " {'text': '裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。',\n",
       "  'extra_text': None,\n",
       "  'text_span1': {'text': '尘土', 'span': (7, 9), 'label': 'span', 'prob': 1.0},\n",
       "  'text_span2': {'text': '它们', 'span': (27, 29), 'label': 'span', 'prob': 1.0},\n",
       "  'label': {'name': 'false', 'prob': 1.0},\n",
       "  'predict': {'name': 'false', 'prob': 0.9980733394622803}},\n",
       " {'text': '裂开的伤口涂满尘土，里面有碎石子和木头刺，我小心翼翼把它们剔除出去。',\n",
       "  'extra_text': None,\n",
       "  'text_span1': {'text': '碎石子和木头刺',\n",
       "   'span': (13, 20),\n",
       "   'label': 'span',\n",
       "   'prob': 1.0},\n",
       "  'text_span2': {'text': '它们', 'span': (27, 29), 'label': 'span', 'prob': 1.0},\n",
       "  'label': {'name': 'true', 'prob': 1.0},\n",
       "  'predict': {'name': 'true', 'prob': 0.9973798394203186}},\n",
       " {'text': '这时候放在床上枕头旁边的手机响了，我感到奇怪，因为欠费已被停机两个月，现在它突然响了。',\n",
       "  'extra_text': None,\n",
       "  'text_span1': {'text': '床', 'span': (5, 6), 'label': 'span', 'prob': 1.0},\n",
       "  'text_span2': {'text': '它', 'span': (37, 38), 'label': 'span', 'prob': 1.0},\n",
       "  'label': {'name': 'false', 'prob': 1.0},\n",
       "  'predict': {'name': 'false', 'prob': 0.9944508075714111}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = get_relation_classify_output(to_pred, pred)\n",
    "output_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:34:39.451183Z",
     "start_time": "2021-08-04T07:34:39.419894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Label(name='false', prob=1.0),\n",
       " Label(name='false', prob=1.0),\n",
       " Label(name='true', prob=1.0),\n",
       " Label(name='false', prob=1.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Label(name='false', prob=0.9941636919975281),\n",
       " Label(name='false', prob=0.9980733394622803),\n",
       " Label(name='true', prob=0.9973798394203186),\n",
       " Label(name='false', prob=0.9944508075714111)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'true': {'tp': 1,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'false': {'tp': 3,\n",
       "   'fp': 0,\n",
       "   'fn': 0,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0}},\n",
       " 'micro': {'tp': 4,\n",
       "  'fp': 0,\n",
       "  'fn': 0,\n",
       "  'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1': 1.0},\n",
       " 'macro': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = [e.label for e in to_pred]\n",
    "true_labels\n",
    "pred\n",
    "\n",
    "eval_rs = eval_relation_classify(true_labels, pred)\n",
    "eval_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save&load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:34:43.657763Z",
     "start_time": "2021-08-04T07:34:41.614338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'h5'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./models/tf_relation_classify_model'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:34:41 [INFO][core.py:74]:saving model to ./models/tf_relation_classify_model\n",
      "2021-08-04 15:34:41 [INFO][tf_core.py:56]:saving keras model to path:./models/tf_relation_classify_model/nn_model/nn_model.h5\n",
      "2021-08-04 15:34:43 [INFO][core.py:126]:save model done\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"./models/{model.model_name}\"\n",
    "save_args = dict(**config[\"common_config\"][\"save_args\"])\n",
    "del save_args[\"tf_serving_version\"]\n",
    "\n",
    "save_args\n",
    "model_path\n",
    "\n",
    "\n",
    "model.save(path=model_path, **save_args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:34:49.097797Z",
     "start_time": "2021-08-04T07:34:45.661092Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 15:34:45 [INFO][core.py:85]:loading model from path:./models/tf_relation_classify_model\n",
      "2021-08-04 15:34:45 [INFO][core.py:42]:init model with config:\n",
      "2021-08-04 15:34:45 [INFO][core.py:45]:{\n",
      "    \"tokenizer_config\": {\n",
      "        \"tokenizer_name\": \"bert_word_piece\",\n",
      "        \"tokenizer_args\": {\n",
      "            \"vocabs\": \"/nfs/pony/chenhao/pretrain/chinese_rbt4_L-4_H-768_A-12/vocab.txt\"\n",
      "        }\n",
      "    },\n",
      "    \"task_config\": {\n",
      "        \"label_file_path\": \"/nfs/pony/chenhao/data/clue/wsc/labels.txt\",\n",
      "        \"text_span_label_path\": \"/nfs/pony/chenhao/data/clue/wsc/span_labels.txt\",\n",
      "        \"max_len\": 128,\n",
      "        \"multi_label\": false,\n",
      "        \"embedding_strategy\": \"ENTITY_START\"\n",
      "    },\n",
      "    \"model_name\": \"tf_relation_classify_model\",\n",
      "    \"model_cls\": \"TFRelationClassify\",\n",
      "    \"model_dict\": {\n",
      "        \"test\": {\n",
      "            \"model\": \"model_1\",\n",
      "            \"type_info\": {\n",
      "                \"token_ids\": \"int32\",\n",
      "                \"segment_ids\": \"int32\",\n",
      "                \"span_idxs\": \"int32\"\n",
      "            },\n",
      "            \"shape_info\": {\n",
      "                \"token_ids\": [\n",
      "                    null\n",
      "                ],\n",
      "                \"segment_ids\": [\n",
      "                    null\n",
      "                ],\n",
      "                \"span_idxs\": [\n",
      "                    4\n",
      "                ]\n",
      "            }\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"model\": \"model_2\",\n",
      "            \"type_info\": {\n",
      "                \"token_ids\": \"int32\",\n",
      "                \"segment_ids\": \"int32\",\n",
      "                \"span_idxs\": \"int32\",\n",
      "                \"classify_output\": \"int32\"\n",
      "            },\n",
      "            \"shape_info\": {\n",
      "                \"token_ids\": [\n",
      "                    null\n",
      "                ],\n",
      "                \"segment_ids\": [\n",
      "                    null\n",
      "                ],\n",
      "                \"span_idxs\": [\n",
      "                    4\n",
      "                ],\n",
      "                \"classify_output\": []\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2021-08-04 15:34:45 [INFO][tf_relation_classify.py:70]:initializing tokenizer\n",
      "2021-08-04 15:34:45 [INFO][tf_relation_classify.py:77]:replacing special tokens:['[S:span]', '[O:span]', '[/S]', '[/O]'] to vocabs\n",
      "2021-08-04 15:34:45 [INFO][tf_core.py:157]:loading keras model from path:./models/tf_relation_classify_model/nn_model/nn_model.h5 with format:h5\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:192]:Model: \"model_1\"\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:193]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:195]:==================================================================================================\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:token_ids (InputLayer)          [(None, None)]       0                                            \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:segment_ids (InputLayer)        [(None, None)]       0                                            \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:span_idxs (InputLayer)          [(None, 4)]          0                                            \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:model (Model)                   (None, None, 768)    44974080    token_ids[0][0]                  \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:                                                                 segment_ids[0][0]                \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:tf_op_layer_strided_slice (Tens (None, 2)            0           span_idxs[0][0]                  \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:token_extract_layer (TokenExtra (None, 1536)         0           model[1][0]                      \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:259]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:190]:classify_layer (Dense)          (None, 2)            3074        token_extract_layer[0][0]        \n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:257]:==================================================================================================\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:268]:Total params: 44,977,154\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:269]:Trainable params: 44,977,154\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:270]:Non-trainable params: 0\n",
      "2021-08-04 15:34:49 [INFO][layer_utils.py:271]:__________________________________________________________________________________________________\n",
      "2021-08-04 15:34:49 [INFO][core.py:140]:load model done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<config_ai.models.relation_classify.tf_relation_classify.TFRelationClassify at 0x7f61f8254320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model(path=model_path)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:35:02.371339Z",
     "start_time": "2021-08-04T07:35:02.276943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2229.83it/s]\n",
      "2021-08-04 15:35:02 [INFO][tf_core.py:204]:predicting with tf model...\n",
      "2021-08-04 15:35:02 [INFO][utils.py:102]:function:_model_predict cost:0.051 seconds\n",
      "2021-08-04 15:35:02 [INFO][utils.py:102]:function:_post_predict cost:0.002 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Label(name='false', prob=0.9941636919975281),\n",
       " Label(name='false', prob=0.9980733394622803),\n",
       " Label(name='true', prob=0.9973798394203186),\n",
       " Label(name='false', prob=0.9944508075714111)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pred = loaded_model.predict(data=to_pred, threshold=0.5)\n",
    "loaded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:35:23.270020Z",
     "start_time": "2021-08-04T07:35:23.127989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RelationClassifyExample(text='杨百顺他爹是个卖豆腐的。别人叫他卖豆腐的老杨。', extra_text=None, text_span1=TextSpan(text='杨百顺', span=(0, 3), label='span', prob=1.0), text_span2=TextSpan(text='他', span=(15, 16), label='span', prob=1.0)),\n",
       " RelationClassifyExample(text='杨百顺他爹是个卖豆腐的。别人叫他卖豆腐的老杨。', extra_text=None, text_span1=TextSpan(text='杨百顺他爹', span=(0, 5), label='span', prob=1.0), text_span2=TextSpan(text='他', span=(15, 16), label='span', prob=1.0)),\n",
       " RelationClassifyExample(text='老孔说话声儿细；老窦是个急性子，当年一脚把我的鼓给踹破了。我也没输给他，回头一脚，把他的摊子也踢了，胡辣汤流了一地。', extra_text=None, text_span1=TextSpan(text='老窦', span=(8, 10), label='span', prob=1.0), text_span2=TextSpan(text='他', span=(42, 43), label='span', prob=1.0)),\n",
       " RelationClassifyExample(text='老孔说话声儿细；老窦是个急性子，当年一脚把我的鼓给踹破了。我也没输给他，回头一脚，把他的摊子也踢了，胡辣汤流了一地。', extra_text=None, text_span1=TextSpan(text='老孔', span=(0, 2), label='span', prob=1.0), text_span2=TextSpan(text='他', span=(42, 43), label='span', prob=1.0))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3071.63it/s]\n",
      "2021-08-04 15:35:23 [INFO][tf_core.py:204]:predicting with tf model...\n",
      "2021-08-04 15:35:23 [INFO][utils.py:102]:function:_model_predict cost:0.086 seconds\n",
      "2021-08-04 15:35:23 [INFO][utils.py:102]:function:_post_predict cost:0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "tmp_data = model.jload_lines(\"/nfs/pony/chenhao/data/clue/wsc/test.jsonl\")\n",
    "tmp_data = tmp_data[:4]\n",
    "tmp_data\n",
    "\n",
    "\n",
    "loaded_pred = loaded_model.predict(data=tmp_data,threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "chenhao-py3.6-tf2.0",
   "language": "python",
   "name": "chenhao-py3.6-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "508px",
    "left": "1088px",
    "right": "20px",
    "top": "120px",
    "width": "333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
